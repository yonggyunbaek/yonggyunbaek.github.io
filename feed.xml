<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://yonggyunbaek.github.io/</id><title>yonggyun</title><subtitle>A minimal, responsive, and powerful Jekyll theme for presenting professional writing.</subtitle> <updated>2023-05-15T22:02:07+09:00</updated> <author> <name>yonggyun</name> <uri>https://yonggyunbaek.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://yonggyunbaek.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://yonggyunbaek.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator> <rights> © 2023 yonggyun </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>csv파일 spark이용해서 kudu저장</title><link href="https://yonggyunbaek.github.io/posts/csv_spark_kudu/" rel="alternate" type="text/html" title="csv파일 spark이용해서 kudu저장" /><published>2023-04-18T00:00:00+09:00</published> <updated>2023-05-15T21:57:32+09:00</updated> <id>https://yonggyunbaek.github.io/posts/csv_spark_kudu/</id> <content src="https://yonggyunbaek.github.io/posts/csv_spark_kudu/" /> <author> <name>yonggyun</name> </author> <category term="cloudera" /> <summary> csv –&amp;gt; spark –&amp;gt; kudu 1. Load and prepare the CSV data kudutest.csv A,B,NUM,DT a,b,1,2023-02-27 14:52:06 c,d,2,2023-02-27 15:00:00 e,f,3,2023-02-27 16:00:00 HADOOP_USER_NAME=hdfs spark3-shell --jars /opt/cloudera/parcels/CDH/lib/kudu/kudu-spark3_2.12.jar import org.apache.spark.sql.types._ val kdtest = spark.sqlContext.read.format("csv").option("header","true").option("inferSchema","... </summary> </entry> <entry><title>hive create table error(field.delim)</title><link href="https://yonggyunbaek.github.io/posts/hive_field_delim_error/" rel="alternate" type="text/html" title="hive create table error(field.delim)" /><published>2023-04-05T00:00:00+09:00</published> <updated>2023-04-06T01:41:43+09:00</updated> <id>https://yonggyunbaek.github.io/posts/hive_field_delim_error/</id> <content src="https://yonggyunbaek.github.io/posts/hive_field_delim_error/" /> <author> <name>yonggyun</name> </author> <category term="cloudera" /> <summary> 작업배경 테이블 migration 진행 기존 클러스터에서 show create 이용해서 ddl 추출 후 신규 클러스터에서 실행 Error: Error while compiling statement: FAILED: ParseException line 8:1 cannot recognize input near ‘’,\n’’ ‘serialization’ ‘.’ in table properties list (state=42000,code=40000) 1. 추출한 ddl 확인 CREATE EXTERNAL TABLE `default`.`customers_4`( `name` string, `purchanse_count` int) ROW FORMAT SERDE 'org.apache.had... </summary> </entry> <entry><title>hive metastore에서 테이블 리스트 추출</title><link href="https://yonggyunbaek.github.io/posts/hive_metastore_db_tables/" rel="alternate" type="text/html" title="hive metastore에서 테이블 리스트 추출" /><published>2023-03-19T00:00:00+09:00</published> <updated>2023-04-18T00:41:54+09:00</updated> <id>https://yonggyunbaek.github.io/posts/hive_metastore_db_tables/</id> <content src="https://yonggyunbaek.github.io/posts/hive_metastore_db_tables/" /> <author> <name>yonggyun</name> </author> <category term="cloudera" /> <summary> metastore 가 mariadb로 설치된 상태 1. db_name, tbl_name 형태로 추출하기 select name AS db_name,tbl_name FROM TBLS INNER JOIN DBS ON TBLS.DB_ID = DBS.DB_ID WHERE DBS.name='default' 1) 응용(테이블 리스트 추출해서 msck repair 하는 쿼리로 만들기) mysql -u${user} -p${password} metastore -N -e "select concat('msck repair table ', DBS.name,'.',TBLS.tbl_name,' drop partitions;') FROM TBLS INNER JOIN DBS ON TBLS.DB_ID = DBS.DB_ID WH... </summary> </entry> <entry><title>hive,impala - jdbc,odbc 연결</title><link href="https://yonggyunbaek.github.io/posts/hive,impala_jdbc,odbc/" rel="alternate" type="text/html" title="hive,impala - jdbc,odbc 연결" /><published>2023-02-07T00:00:00+09:00</published> <updated>2023-04-17T21:36:28+09:00</updated> <id>https://yonggyunbaek.github.io/posts/hive,impala_jdbc,odbc/</id> <content src="https://yonggyunbaek.github.io/posts/hive,impala_jdbc,odbc/" /> <author> <name>yonggyun</name> </author> <category term="cloudera" /> <summary> 1. cloudera hive,impala JDBC,ODBC 다운로드 https://www.cloudera.com/downloads/connectors/impala/jdbc/2-6-29.html.html https://www.cloudera.com/downloads/connectors/impala/odbc/2-6-17.html https://www.cloudera.com/downloads/connectors/hive/jdbc/2-6-21.html https://www.cloudera.com/downloads/connectors/hive/odbc/2-6-13.html hive, impala 서비스 ldap 설정 상태 1) Impala JDBC pip3 install JayDebeAPI ... </summary> </entry> <entry><title>YARN scheduler (추가 예정)</title><link href="https://yonggyunbaek.github.io/posts/yarn_scheduler/" rel="alternate" type="text/html" title="YARN scheduler (추가 예정)" /><published>2022-12-21T00:00:00+09:00</published> <updated>2022-12-21T21:58:58+09:00</updated> <id>https://yonggyunbaek.github.io/posts/yarn_scheduler/</id> <content src="https://yonggyunbaek.github.io/posts/yarn_scheduler/" /> <author> <name>yonggyun</name> </author> <category term="cloudera" /> <summary> 1. Fair scheduler 자원 경합시 설정한 비율만큼 할당 받음 2. capacity scheduler 미리 예약해둔 queue만큼 자원 사용 </summary> </entry> </feed>
